<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=windows-1252">
<META NAME="Generator" CONTENT="Microsoft Word 97">
<TITLE>HUPO Proteomics Standards Initiative</TITLE>
</HEAD>
<BODY LINK="#0000ff" VLINK="#800080">
<a href="http://psidev.sourceforge.net"><img
								  src="../../images/psi.gif" width="113" height="75" border="0" align=left></a>
<a href="http://www.hupo.org/"><img
				    src="../../images/hupo.gif" width="113" height="75" border="0" align=right></a>
<B><P ALIGN="CENTER">Minutes of the <br>HUPO Proteomics Standards Initiative Meeting </P>
<P ALIGN="CENTER">Hinxton, Cambridge, UK, </P>
<P ALIGN="CENTER">October 19 and 20, 2002.</P>
<P ALIGN="CENTER"></P>
<P>Introduction </B>
<br>
The forum was opened with a brief introduction by Rolf Apweiler who
	outlined the background to the current meeting. At the April
	2002 meeting jointly organised by HUPO and NAS, the
	<em>Proteomics Standards Initiative</em> was formed, whose
	remit is to define and promote standards which will allow free
	exchange and comparison of proteomics data. It was decided
	that this would first be addressed in the fields of mass
	spectrometry and protein-protein interactions (PPI). This
	inaugural meeting of the Proteomics Standards Initiative has
	brought together representatives from the data producer,
	database producer, user and software producer communities who
	are seen as essential in establishing and maintaining the
	required standards.</P> 

<B><P>Alvis Brazma, EBI: The <a href="http://www.mged.org/">MGED</a> standardisation process </B><br>
The expression array community have gone through a similar realisation that a public repository was required where data could be freely accessed by laboratory workers and bioinformaticians, and that a common standard needed to be developed which would allow the transfer of such data between user and databases. It was felt the that the lessons learned from their experience would give the PSI a valuable insight into the problems ahead.</P>

<P>MGED first identified those parts of the problem that were effectively being dealt with by other groups such as the standardization of gene names and gene annotation (GO). They then concentrated their efforts to issues unique to the microarray field, recognising that this required 2-tiered thinking, identifying what could be rapidly implemented and what were more longer- term requirements.</P>

<UL>
<LI>Standardization of experimental procedures - maintained in protocols.</LI>
<LI>Experimental platform - chip design</LI>
<LI>Information processing</LI>
<LI>Nature and structure of data and annotation complex - including development of controlled vocabularies.</LI></UL>


<P>MGED is now the international organisation for facilitating sharing of functional genomic and proteomic data and has developed two working standards - MIAME and MAGE-OM(ML).</P>

<P>MIAME is the annotation standard and outlines the minimum information required to unambiguously interpret and potentially reproduce any array based expression experiment. Several key journals have adopted a checklist based on this standard and will require submission to a public repository before publishing any data. MAGE-OM is an XML-based exchange format which has been developed and adopted by the OMG as the standard for microarrays. Data standardization and normalisation was recognised as being a second part of the process, which was not feasible to implement immediately. MAGE-OM has been adopted by manufacturers and will be used to develop data analysis software as well as public repositories and LIMS systems.</P>

<P>The meeting then divided into 2 parallel sessions - Mass spectrometry and PPI</P>

<h3>Summary</h3>
<B>
<h4>Mass Spectrometry</h4>
</B>
<ul>
<li>A repository of mass spectrometry data is only useful if it stores
	      the data in the context of the workflow of a complete
	      proteomics experiment.
<LI>Three workgroups have been established:</LI>
<UL>
<LI>Definition of MS data and MS data analysis</LI>
<LI>Modelisation of sample preparation</LI>
<LI>Use cases - demands of a public repository for MS data</LI>
</UL>
<LI>Workgroups have defined remit and components</LI>
<LI>Group discussions will be continued via email. 
Each group to document discussion and send results to 
<a href="mailto:weimin@ebi.ac.uk">Weimin</a> for collation 
and circulation of draft proposals</LI>
<LI>Draft document to be presented at session before <a href="http://www.hupo.org/new/congress1/index.html">HUPO conference in Versailles</a>.</LI></UL>
</UL>

<B>
<P>Protein-protein interactions</P>

<UL>
</B><LI>Agreement to define a common standard for protein interaction data exchange.
<li>The standard will have multiple levels. Level 1 will define a basic standard for the exchange
of core interaction data. 
Higher levels will introduce more complex detail data and will be developed subsequently.</LI>
<LI>The <a href="#ppi-format">elements to be contained in the exchange format</a> have been defined.</LI>
<LI>A draft standard will be circulated before 6th November, 
    partners will reconvene in Versailles at the HUPO conference and 
    will meet to finalise the draft in January.</LI>
<LI>A proposal for Level 1 will be made public within 6 months.</LI></UL>
</UL>

<hr>
<h3>Detailed reports</h3>
<h4> Mass Spectrometry</H4>

Chair: Rolf Apweiler, Weimin Zhu, EBI
<P>The meeting could be summarised as a discussion of two questions:</P>

<OL TYPE="i">

<LI>what is the use of  standards in the field of mass-spectrometry?</LI></OL>

<OL START=2 TYPE="i">

<LI>if a repository is set up, what is its purpose?</LI></OL>


<P>Following presentations on various aspects of mass spectrometry, the group received a demonstration of PEDRo, a tool developed at the University of Manchester to capture data and meta data from proteomics experiments that include mass spectrometry as one component.  PEDRo has been designed according to the MGED guidelines and has a similar scope to the micro array data model, capturing the complete process of scientific experiment from hypotheses formation through to peak identification. A consideration of PEDRo led to the raising of questions that continued to be discussed throughout the meeting, such as: what is proteomics? Is it one thing or many? And if it is many things, do we need separate standards for each type of experiment, with separate repositories for each type of data?  As the complications involved became apparent, questions of feasibility were also raised.  The example of BIORAD's workspace was given.  Originally an ambitious plan to design software that supported data from all types of proteomics experiments, it had been replaced by a less ambitious project aimed at capturing one particular work-flow.</P>

<P>Subsequently, the following specific points were discussed.</P>

<OL>

<U><LI>The purpose of new repositories.</U> One purpose was to provide an audit trail for publications, so that the producers of bulk or complex data would be able to fully describe (and be held to account for) methodologies that could not appear in print medium; this would require the co-operation of journals. Another purpose was to provide an implementation to allow the user to explore/mine the data, preferably in biological context.  Important concepts here are &quot;the minimal description of the experiment&quot; and &quot;validation criteria&quot;.</LI>

	  <li><u>The scope of the standardization effort:</u> 
<ul>
	<li>Hardware: environment settings (calibration parameters), generic raw data format(?).<br>
	<li>Software and data: environment settings (parameters etc.), generic data format, sequence database to be searched against, algorithms for noise reduction and peptide interpretations.<br>
  	<li>Experiments: types of platforms (such as MS/MS, ion trap) and their required procedures, experiment quality (sample preparations, spectra and statistics criteria for peptide/protein hits), quantification or qualification requirements.<br>
    	<li>Samples: sample quality, types, and conditions, sample preparation / separation methods.
</ul>

</li>

<U><LI>How many repositories?</U>  Component-based approach, with different repositories for different types of proteomics experiment,  was considered, but fears were expressed that this would disrupt the audit trail or make biological interpretation of the data impossible.  How to capture the meaningful results of an experiment, (which may be, for example, a conclusion that two proteins interacted) without a wasteful overlap with PPI databases was discussed at intervals throughout the meeting, with many expressing a desire to collaborate with the PPI working group on this issue.</LI>


<U><LI>Would the users enter all the data?</U> The hope was expressed that if a standard could be produced, LIMS systems might automatically produce compliant output. However, proteomics is often not fully automated and many data points might be missing.</LI>


<LI><U>Participation of equipment manufacturers.</U>  The view was expressed that the participation of equipment manufacturers was essential to the ultimate success of any new standard</LI>
<U>
</U><LI><U>Co-operation with MGED/GOBO.</U>  In areas such as hypotheses description and preliminary sample preparation, substantial opportunities for overlap with other groups involved in standardization were perceived, and enthusiasm expressed for taking these forward.</LI>


<U><LI>Pre-existing mass-spec standards.</U>  Certain pre-existing standards already exist for mass spectrometry, the NET-CODF and the ANOI standards.</LI>
<U>
<LI>Error Rates.</U>  There is little public awareness among potential users of the data of problems like estimating error and the statistical complexity in producing the final protein identifications.  We need to raise community awareness of these issues.</LI>

</OL>


<U><P>Initial conclusions</U>:</P></U>

<P>Mass spectrometry data exists at many levels: from raw data through  peak lists  and   peptide identification to protein identification; on top of this is the desire to mine data.  Huge amounts of variation (and manual interpretation) exist in the processes that effect these transformations.   2 approaches of MGED to analogous problems were considered:</P>

<OL TYPE="i">

<LI>Deal with the problem of the variety of potential workflows by considering an experiment to consist recursively of a sequence of data sets with transformations between them.</LI>
<LI>Build an comprehensive model without an a priori commitment to complete implementation</LI></OL>


<P>The group then decided to split into smaller working parties to consider more limited aspects of the problem. The following section contains the reports which have been communicated by mail after the meeting.</P>

	&nbsp;&nbsp;&nbsp;&nbsp;<b><u>Group 1: MS workgroup <br></u></b>
	&nbsp;&nbsp;&nbsp;&nbsp;<b>Coordinator</b>: Steffen Möller.<br>  
	&nbsp;&nbsp;&nbsp;&nbsp;<b>Group focus</b>: modelling the representations of raw data and its interpretation.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;<b>Key points</b>:<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- MS whole peaklists are captured, which are described by the hardware (vendor, ionisation source and type) used and its settings (configuration file). <br>
	&nbsp;&nbsp;&nbsp;&nbsp;- A spectrum can be a collection of references to a set of other spectra. The former can be a whole MS spectrum, and the latter can be a better defined spectra such as those from MS/MS.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- All the interpreted peptides putatively found to be associated with specific spectrum, by certain software, are captured only once, which are also annotated by respective post-translational modifications. Protein identifications are the another layer of data interpretation, which is referenced to a subset of peptides.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;A UML model reflecting the above key points was generated. There are 3 main components in the model (The following summary has integrated Gregoire’s suggestions. Both UML diagrams are available <a href="group1.html">HERE</a> for details).<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Peaklist: include attributes such as peak detection methods, MS experiment methods, and fragments;<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Peptide and protein hits: include attributes of sequences, PTM, external reference databases;<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Identification Run: it is a link to associate the above two components, which includes the attributes of peptide/protein identification methods, external reference databases, scoring/ranking criteria.<br><br>
			
	&nbsp;&nbsp;&nbsp;&nbsp;<u><b>Group 2: Pre-MS workgroup</u></b><br>
	&nbsp;&nbsp;&nbsp;&nbsp;<b>Coordinator</b>: Kathryn Lilley.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;<b>Group focus</b>: determining required upstream components need to be recorded.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;<b>Key points</b>: <br>
	&nbsp;&nbsp;&nbsp;&nbsp;- The recorded information should satisfy:<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;minimum requirements for publication<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;minimum requirements enabling repeating and comparing data.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- The aim of the experiment/study.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- The sample sources: tissue/cell type, treatment/condition, origin etc.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- Sample preparations: methods to harvest sample, to extract proteins, protein concentration determination, as well as some quality controls, such as checking for proteolysis, reproducibility of protein extraction, contaminants.
- Sample separation and detections: separation methods, suchas electrophoresis (SDS-PAGE, IEF and FFE) or chromatography (SCX, RP, IMAC, Affinity), and detection methods.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;A <a href="group2.html">flow chart </a>has been produced to describe the relationships of those components. <br>&nbsp;&nbsp;&nbsp;&nbsp;The key points are:<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Different separation methods can be chained each other, so that,<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Sample should be attached with its separation status, which is supported by defining sample as a recursive component in the model. <br><br>

	&nbsp;&nbsp;&nbsp;&nbsp;<u><b>Group 3: Use case workgroup</u></b><br>
		&nbsp;&nbsp;&nbsp;&nbsp;<b>Group coordinator</b>: Pierre-Alain Binz<br>
		&nbsp;&nbsp;&nbsp;&nbsp;<b>Group focus</b>: the questions (wish list) the data repository should be able to answer.<br>
		&nbsp;&nbsp;&nbsp;&nbsp;<b>Key points</b> (Summarize based on Chris Taylor’s report):<br>
			&nbsp;&nbsp;&nbsp;&nbsp;- Types of users the repository should support: <br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experts on proteome bioinformatics, proteome, MS<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;General scientists having specific interests, such as specific protein and organism.<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data integrator: to/from other data sources.<br>
			&nbsp;&nbsp;&nbsp;&nbsp;- Sample queries(G: general, E: experts, I, data integrator):<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G: Sample condition changes, look for some protin pattern changes (under/over expressed, modified, interacting etc.)<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E: From a similar sample, identify a similar protein?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E: What happen to protein X in condition Y?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E: What is the known interpretation of spectrum A?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G+E: Is protein X already documented?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G+E: What are the criteria should applied to data as QC?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G+E+I: How the data produced?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G: What experiments contain protein with acc# X?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G+I: Which experiments contain gels having protein with name‘xxx’?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G+E: Which experiments contains proteins from organism X?<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E+I: Return all proteins within the specified pi, length/mass range.<br>
			&nbsp;&nbsp;&nbsp;&nbsp;- Query attribute list: <br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Protein name /ID<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sequence<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PTM<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Peaklists (PMF and MS/MS)<br>
			&nbsp;&nbsp;&nbsp;&nbsp;- Output attribute list:<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;All the query attributes<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Biology environments<br>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quantitation<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experiemental process<br>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;External references<br>
			&nbsp;&nbsp;&nbsp;&nbsp;- Data Quality and Validation <br><br>


<b>Future directions:</b><br>
	&nbsp;&nbsp;&nbsp;&nbsp;- Clearly define the scope of the standardization. <br>
	&nbsp;&nbsp;&nbsp;&nbsp;- Looking for levelled approaches. The level 1 should have a clearly defined model, which is sensible, but feasible to achieve. The guideline could be something as workgroup 2 suggested:<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. Minimum requirements for publication;<br>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Minimum requirement for data comparison and data repeat.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;In order to allow the model flexible enough for future modifications, and expanding, the model should be built upon a set of well-defined components.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- User case group should work closer with other 2 groups, to help scoping, validating the model for level 1.<br>
	&nbsp;&nbsp;&nbsp;&nbsp;- Get more industry leaders, such as hardware and software vendors, involved.<br>

<P>It was decided that the working groups should continue to research their own areas, communicating with the aid of email and a password-controlled website, with the aim of producing a draft standard ASAP.</P>


<hr>

<a name="ppi-detail">
<h4>Protein-Protein Interactions</h4>
Chair: Henning Hermjakob, EBI

<P>The session commenced with brief presentations 
by database providers represented at the meeting.</P>

<B><P>Database of Interacting Proteins (<a href="http://dip.doe-mbi.ucla.edu/">DIP</a>): Ioannis Xenarios, UCLA </B><br>
DIP originally only contained PPI experimentally determined by X-ray crystallography and was developed as a tool to benchmark predictions. The database cross-references to original papers and procedures but makes no interpretation step. Literature data is now included to give a low-coverage, highly annotated database which can be freely downloaded by academics in flat-file or XML format. DIP currently contains 18000 interactions, and 2000 journal references.</P>

<B><P>A Platform for the Integration and Analysis of PPI Data: Jerome Wojcik, <a href="http://www.hybrigenics.com/">Hybrigenics S.A.</a> </B><br>This database was built with the aim of cataloguing PPI identified in a high throughput manner for eventual drug target identification to be confirmed in cellular assays. 2-hybrid experiments are performed using one bait molecule against a library of random expressed transcipts, identification of positive hits potentially results in a number of peptide fragments from the same protein being identified and a selected interacting domain (SID) within that protein being described. A confidence code is attached, once the SID has been identified, which takes into account false positive reactions and gives the user confidence that all interactions are biochemically, if not necessarily biologically, relevant. </P>
<p>Requirements for a PPI standard:
<ul>
<li>exhaustive and unambiguous interactor identification
			<li>explicit data source
			  <li>experimental data type
			    <li>intellectual property status
			      <li>avoid redundancy
				<li>annotation on interaction, e.g. quality scores
</ul>

<B><P>The Biomolecular Interaction Network Database (<a href="http://bind.ca">BIND</a>): Chris
		      Hogue, Samuel Lunenfeld Research Institute,
		      Toronto</B><br>BIND archives and exchanges
		    molecular assembly information and contains
		    details on interactions, complexes and pathways. A
		    BIND entry points to 2 objects annotated in other
		    databases, typically RefSeq. BIND is available in
		    ASN.1 and XML and includes update metadata such as
		    submitters details, history information and an
		    audit trail as part of a schema published in a
		    peer-reviewed journal. BIND intend to act as both
		    a primary and secondary database; RefBIND will be
		    curated, containing structural information and add
		    literature support evidence. BIND has recently
		    received major funding, mainly for a large-scale
		    literature curation effort.</P> 

<B><P>Molecular Interaction Database (<a href="http://cbm.bio.uniroma2.it/mint/">MINT</a>): Gianni Cesareni, University of Rome. </B><br>MINT stores manually annotated interactions and enzymic modifications taken from the literature, in addition to original phage display data. Mint contains 3800 manually curated interactions, thereof 1799 of mammalian origin.</P> Authors of relevant publications in FEBS letters are now kindly requested to submit their interaction data to MINT <em>after</em> their papers have been accepted. About 50% of the authors do submit their data subsequently.

<B><P>Holger Husi, Centre for Neurosciences, Edinburgh. </B><br><a href="http://www.anc.ed.ac.uk/mscs/PPID/">PPID</a>, is a database of neurological receptors based on the isolation of complexes and characterisation of binding partners. Literature and homology data has also been included. Splice sites, signal peptides, localisation domains, PPI and Protein DNA interactions are identified in rat, mouse and human tissue.</P>

<B><P>Gene Interaction Networks DB (GIN-DB): Bernard Jacq, LGPD-CNRS,
			  Developmental Biology Institute of
			  Marseilles. </B><br>
GIN-DB concentrates on 4 model organisms (yeast, drosophila, mouse 
and human) and 4 interaction types (PPI, protein-DNA, protein-RNA and 
genetic). The database is used internally to study eukaryotic 
molecular and genetic networks, transcriptional networks, evolution 
of networks, to make functional comparisons of proteins, and to 
perform dynamic modelling of networks. In order to study protein 
function using PPIs, a functional distance is calculated between 
proteins, taking into account all individual and shared interacting 
partners. Cluster analysis of these distances then shows proteins of 
shared cellular function to nest together. An information extraction 
program has been developed in order to help annotators to extract 
interaction information from Medline and to transfer it to the 
database after human validation. The database, under development with 
the Oracle RDBMS, will be accessible from Spring 2003.
</P>
<p>
Requirements for PPI standard:
<ul>
			    <li>controlled vocabularies for interaction partners, domains
			      <li>controlled vocabulary for methods,
				interaction "output" (activation,
				inhibition, ...)
				<li>integration with other data types
</ul>
<B><P><a href="http://www.ebi.ac.uk/intact/">IntAct</a>: Henning Hermjakob, EBI </B><br>IntAct is designed
			  primarily as a public repository of PPI
			  data. The IntAct beta release is planned for
			  December 2002.
Open source software will allow local installation of IntAct nodes to 
				    facilitate the analysis of 
private, confidential data in the context of publicly available data, and to facilitate submission
to public databases after publication of the data. 
The data structure models both binary and n-ary (complex) interactions. 
A focus of the IntAct project is the development of controlled vocabularies (CVs).
</P>

<B><P>IntAct Controlled Vocabularies: Luisa Montecchi-Palazzi, University of Rome</B>.<br> 
A number of controlled vocabularies are under development. 
A CV for post translational modifications has been based on the 
<A HREF="http://home.earthlink.net/~jsgaravelli/RESIDInfo.HTML">RESID database</A>, 
a well-annotated controlled vocabulary for experimental methods for identifying PPI has been collated
and will be made available to the scientific community via 
<a href="http://www.geneontology.org">GOBO</a>.

<B><H3>Protein-Protein Interaction Open Session: Towards a common standard for data exchange</h3>
</B>
<B><P>Is there a requirement for a community standard?
</B><br>
Data exchange is seen as 
essential for the purposes of data comparison, 
benchmarking and quality control. A community standard should 
allow simple access to core protein interaction data, while being extensible to 
exchange data with a high level of detail.
Many users will require only simple indexing and interface systems, 
larger organisations will have more complex requirements but 
will have the infrastructure to develop much of this themselves. 
The problem of confidential data was discussed, this can be flagged and retained 
by the parent database as already happens in sequence databases.
<B> </B>A minimum standard for data exchange needs to be 
developed and a formal mechanism for monitoring and maintaining this standard put in place. 
The MGED model for this can be used, where appropriate.</P>

<B><P>Definition of Use Cases </B>
The potential use of the data had to be understood before 
the minimum common standard could be defined. 
Most groups were interested in making graphical representations of PPIs 
and in making inter-species comparisons or homology models. 
For this, details of species, strain and in some cases tissue, 
cell type and disease state are of importance. 
Domain identification and the dynamic properties of PPI 
were also common requirements whilst the functional outcome of PPI and 
the effects of mutations were also seen as desirables. 
Some users have a requirement for in-depth experimental detail, 
however this was felt to be beyond the scope of a data exchange format and 
would have to be retrieved from the literature. 
PubMed I.D.s were seen as essential when available but would not be required 
since this would compromise the transfer of unpublished data between 
collaborating laboratories.</P>

<B><P>Outline Data Structure </B>
The need for a levelled approach was soon recognised, 
with Level 1 designed to fulfil basic requirements and 
be suitable for rapid implementation with subsequent levels 
containing more features whilst remaining backwards compatible. 
Level 1 would address PPI data only, 
interactions with nucleic acids and small molecules would be formally 
covered in Level 2, although the exchange model may prove flexible enough 
for this to be possible at Level 1. It was also proposed that Level 1 
should be restricted to binary data but this was felt to be too limiting 
whereas sets of 1-n interactors would allow data on both complexes and 
auto-interactors to be made available for exchange. 
The topology of a particular complex formation could be described within each set.</P>

<P>Each Interchange Format Record will report
an interaction with one or more interactors, supported by one or more experiments.
</p>
<P>The interchange format may be used with hypothetical interactions (in-silico).  </P>

<P>Most databases wanted to be able to accurately represent protein sequence 
in particular when a protein has been modified, 
or is a fragment of a published sequence. It was agreed to use 
accession numbers from public databases whenever possible and annotate changes 
through a feature table. 
The protein sequence must be given if it is not identified by reference to public 
databases, and may always be given.</P>

<P>Each entry will contain the accession number of its parent database. Parent
databases will be identified by a prefix. 
This will require a registry service, which will have to be recognised and maintained. 
The PSI/HUPO should be used as the authority for this and a 
host site will have to be established. 
An operating procedure will be written and maintained.
<p> 
Once PSI PPI level 1 standard is established, the major public database providers will 
collectively
approach journals and funding agencies to request that deposition of published interaction data
in public databases will be required.
</P>

<P>The standardization of experimental design was discussed, 
but this is a far more complex field than that tackled 
by MGED with a more diverse set of techniques available for experimenters. 
It was decided that this was better approached through the development of 
C.V.s to describe the work done rather than imposed standards - 
the work already initiated by the IntAct project was seen as a suitable starting point.  </P>

<P>&nbsp;</P>
<B><P>Administrative Issues and Timelines</P>
</B><P>The initial report will be circulated within 2 weeks, 
any objections should be voiced by the end of November - 
silence will be seen as agreement with the content. 
Two journals have asked for reports of this meeting 
but these will have to completed to a tight deadline and will have to
			      be written 
without full consultation of all the members present at the meeting.  
A potentially closely related effort in facilitating data exchange is being planned by the 
Biopathways Consortium and it was agreed that documentation 
from this meeting should be prepared in time for BIND to represent the PSI 
at this meeting (New York, November 6<SUP>th</SUP>).       <br>
[SEO/PK/HH]</P>

<P>Henning will establish a PPI mailing list - members to submit names of other parties who may be interested in becoming involved.<br>
[HH]</P>

<P>A follow-up meeting is to be organised around  the HUPO World Congress, 21<SUP>st</SUP>-24<SUP>th</SUP> November, Versailles. A full meeting will be held early next year, Marseilles is a possible venue for this.     <br>
[HH/BJ]</P>

<P>An XML draft  is to be produced, with pointers to existing or required C.V.s is to be written and circulated. This is then to be discussed on the mailing list and finalised at the January meeting.<br>
[HH/GB/CH]</P>

<P>Funding for future meetings should be sought - the Wellcome Trust, ESF and industry are all seen as possible sponsors.<br>
[HH]</P>
<a name="ppi-format">
<h4>PSI Molecular Interaction Interchange Format Record Structure:</h4>
				<dl>
				  <dt>1: Required: Sequence Information List
				    <dd>Sequence describes an
				      unambiguous chemical biopolymer
				      (i.e. never a consensus
				      sequence).
				      <ul>
					<li>Required: Unambiguous sequence identifier, normally
			    Accession.version. May be replaced by a
					  local identifier in case of
					  a sequence not in public
					  databases. In this case the
					  sequence is mandatory.
					      <li>Required: Sequence short label, according to standard naming conventions.
					  <li>Optional: Database crossreferences
					    <li>Required: Molecule type (DNA, RNA, AA), extensible to small molecules
						<li>Required: Unique local sequence identifier.
						  <li>Required: NCBI
						    tax ID of source organism
						    <li>Optional: Organism name
						      <li>Optional: Further specification, e.g. tissue, cell line.
							<li>Optional:							  Sequence
							  Instance:
							  for
							  proteins,
							  use 20
							  letter code
							  with PTM
							  modifications in BIND FASTA-PTM format. Example: GDKNADG[Y:po]IEFEEL
				      </ul>

<dt>2: Optional: Feature list</dt>
<dd>Describes sequence features.
<ul>
					  <li>Overlapping features are allowed
					    <li>A feature may cover
					      the length of the entire
					      protein
					      <li>A feature may describe the binding site
						<li>A feature may describe a PTM
					      <li>For each feature:
						<ul>
						  <li>Required: Unique local feature identifier
						</ul>
						<li>Required: Ranges,
						  sites, discontinuous
						  ranges according to
						  Genbank FF format
						  parse rules in a
						  string or an
						  acceptable XML
						  structure. 
						  <li>3: Optional: Structural Domain Annotation (one per feature) with

Interpro/CDD Primary Key.
							<li>Optional: Experimental conditions in which the feature has been identified.

</ul>
<dt>4: Optional: Interaction topology list</dt>
<dd>List of pairs of features that annotate pairs of sites between
					  sequences using pairs of
					  internal identifiers.  With
					  each pair a term from a CV with
					  descriptive information
					  corresponding to the
					  pairwise interaction may be
					  assigned<p>
Example: (p1)F1-F4(p2) <p>
For each feature pair, an interaction description is required.
<dt>5: Required: Experimental Conditions List</dt>
<dd>
<ul>
<LI>Optional: List the feature(s) the experimental condition applies to, or to all (if there are no features, all is implied).</LI>
<LI>Required: Interaction method using ONE C.V. methodology term.</LI.
<LI>Required: Interaction attributes include PMID (if available) and confidence level (if available).</LI>
<LI>Required (if applicable): Methods using host organism MUST provide NCBI tax id. And MAY provide free-text strain info</LI>
<LI>Optional: Exp. Design SHOULD be documented; standard provides minimal structure and recommendation for tissue, keywords</LI>
<LI>Optional: Exp. Conditions SHOULD be documented; standard provides
				      minimal structure with
				      recommendations for
				      keywords</LI>
</ul>


				</dl>
<hr>
<address>Sandra Orchard, Paul Kersey, Weimin Zhu, Henning Hermjakob, <a href="mailto:hhe@ebi.ac.uk">hhe@ebi.ac.uk</a>

</BODY>
</HTML>
